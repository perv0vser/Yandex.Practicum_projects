{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href=\"#Исследование-задачи\" data-toc-modified-id=\"Исследование-задачи-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Исследование задачи</a></span></li><li><span><a href=\"#Борьба-с-дисбалансом\" data-toc-modified-id=\"Борьба-с-дисбалансом-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Борьба с дисбалансом</a></span><ul class=\"toc-item\"><li><span><a href=\"#Взвешивание-классов\" data-toc-modified-id=\"Взвешивание-классов-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Взвешивание классов</a></span></li><li><span><a href=\"#Upsampling\" data-toc-modified-id=\"Upsampling-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Upsampling</a></span></li><li><span><a href=\"#Downsampling\" data-toc-modified-id=\"Downsampling-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Downsampling</a></span></li><li><span><a href=\"#Изменение-порога\" data-toc-modified-id=\"Изменение-порога-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Изменение порога</a></span></li></ul></li><li><span><a href=\"#Тестирование-модели\" data-toc-modified-id=\"Тестирование-модели-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Тестирование модели</a></span></li><li><span><a href=\"#Чек-лист-готовности-проекта\" data-toc-modified-id=\"Чек-лист-готовности-проекта-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист готовности проекта</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из банка стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Требуется построить модель с предельно большим значением *F1*-меры. Чтобы считать проект успешным, нужно довести метрику до 0.59."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки\n",
    "- RowNumber — индекс строки в данных\n",
    "- CustomerId — уникальный идентификатор клиента\n",
    "- Surname — фамилия\n",
    "- CreditScore — кредитный рейтинг\n",
    "- Geography — страна проживания\n",
    "- Gender — пол\n",
    "- Age — возраст\n",
    "- Tenure — сколько лет человек является клиентом банка\n",
    "- Balance — баланс на счёте\n",
    "- NumOfProducts — количество продуктов банка, используемых клиентом\n",
    "- HasCrCard — наличие кредитной карты\n",
    "- IsActiveMember — активность клиента\n",
    "- EstimatedSalary — предполагаемая зарплата\n",
    "\n",
    "Целевой признак\n",
    "- Exited — факт ухода клиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score, precision_score, recall_score, \\\n",
    "roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "pd.options.mode.chained_assignment=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>8689</td>\n",
       "      <td>15778418</td>\n",
       "      <td>Burns</td>\n",
       "      <td>637</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154309.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125334.16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8800</th>\n",
       "      <td>8801</td>\n",
       "      <td>15647890</td>\n",
       "      <td>Su</td>\n",
       "      <td>691</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>37</td>\n",
       "      <td>9.0</td>\n",
       "      <td>149405.18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>146411.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8912</th>\n",
       "      <td>8913</td>\n",
       "      <td>15637354</td>\n",
       "      <td>Yobachukwu</td>\n",
       "      <td>623</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>7.0</td>\n",
       "      <td>148167.83</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>109470.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8748</th>\n",
       "      <td>8749</td>\n",
       "      <td>15673971</td>\n",
       "      <td>Houghton</td>\n",
       "      <td>655</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>44</td>\n",
       "      <td>6.0</td>\n",
       "      <td>146498.76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64853.51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>4400</td>\n",
       "      <td>15572547</td>\n",
       "      <td>Vaguine</td>\n",
       "      <td>670</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>9.0</td>\n",
       "      <td>104930.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155921.81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId     Surname  CreditScore Geography  Gender  Age  \\\n",
       "8688       8689    15778418       Burns          637   Germany    Male   40   \n",
       "8800       8801    15647890          Su          691    France    Male   37   \n",
       "8912       8913    15637354  Yobachukwu          623    France  Female   24   \n",
       "8748       8749    15673971    Houghton          655   Germany  Female   44   \n",
       "4399       4400    15572547     Vaguine          670    France  Female   45   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "8688     9.0  154309.67              1          1               1   \n",
       "8800     9.0  149405.18              1          1               1   \n",
       "8912     7.0  148167.83              2          1               1   \n",
       "8748     6.0  146498.76              1          1               0   \n",
       "4399     9.0  104930.38              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "8688        125334.16       1  \n",
       "8800        146411.60       0  \n",
       "8912        109470.34       0  \n",
       "8748         64853.51       1  \n",
       "4399        155921.81       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('/datasets/Churn.csv') # читаем csv-файл и сохраняем в переменную df\n",
    "except:\n",
    "    df = pd.read_csv('https://code.s3.yandex.net/datasets/Churn.csv') \n",
    "\n",
    "df.sample(5) # смотрим случайные 5 строк из датасета для ознакомления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() # смотрим информацию по датасету: интересуют типы данных, названия столбцов, наличие пропусков, кол-во строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [x.lower() for x in df.columns] # приводим наименования столбцов к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tenure'].isna().sum() # перепроверяем кол-во пропусков в столбце \"tenure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rownumber</th>\n",
       "      <th>customerid</th>\n",
       "      <th>surname</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>15589475</td>\n",
       "      <td>Azikiwe</td>\n",
       "      <td>591</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140469.38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>15766205</td>\n",
       "      <td>Yin</td>\n",
       "      <td>550</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103391.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90878.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>15768193</td>\n",
       "      <td>Trevisani</td>\n",
       "      <td>585</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146050.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86424.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>15702298</td>\n",
       "      <td>Parkhill</td>\n",
       "      <td>655</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125561.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164040.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>15651280</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>742</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136857.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84509.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944</th>\n",
       "      <td>9945</td>\n",
       "      <td>15703923</td>\n",
       "      <td>Cameron</td>\n",
       "      <td>744</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190409.34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138361.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9956</th>\n",
       "      <td>9957</td>\n",
       "      <td>15707861</td>\n",
       "      <td>Nucci</td>\n",
       "      <td>520</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85216.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117369.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>9965</td>\n",
       "      <td>15642785</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>479</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117593.48</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113308.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>9986</td>\n",
       "      <td>15586914</td>\n",
       "      <td>Nepean</td>\n",
       "      <td>659</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123841.49</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96833.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>909 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rownumber  customerid    surname  creditscore geography  gender  age  \\\n",
       "30           31    15589475    Azikiwe          591     Spain  Female   39   \n",
       "48           49    15766205        Yin          550   Germany    Male   38   \n",
       "51           52    15768193  Trevisani          585   Germany    Male   36   \n",
       "53           54    15702298   Parkhill          655   Germany    Male   41   \n",
       "60           61    15651280     Hunter          742   Germany    Male   35   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9944       9945    15703923    Cameron          744   Germany    Male   41   \n",
       "9956       9957    15707861      Nucci          520    France  Female   46   \n",
       "9964       9965    15642785    Douglas          479    France    Male   34   \n",
       "9985       9986    15586914     Nepean          659    France    Male   36   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      tenure    balance  numofproducts  hascrcard  isactivemember  \\\n",
       "30       NaN       0.00              3          1               0   \n",
       "48       NaN  103391.38              1          0               1   \n",
       "51       NaN  146050.97              2          0               0   \n",
       "53       NaN  125561.97              1          0               0   \n",
       "60       NaN  136857.00              1          0               0   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9944     NaN  190409.34              2          1               1   \n",
       "9956     NaN   85216.61              1          1               0   \n",
       "9964     NaN  117593.48              2          0               0   \n",
       "9985     NaN  123841.49              2          1               0   \n",
       "9999     NaN  130142.79              1          1               0   \n",
       "\n",
       "      estimatedsalary  exited  \n",
       "30          140469.38       1  \n",
       "48           90878.13       0  \n",
       "51           86424.57       0  \n",
       "53          164040.94       1  \n",
       "60           84509.57       0  \n",
       "...               ...     ...  \n",
       "9944        138361.48       0  \n",
       "9956        117369.52       1  \n",
       "9964        113308.29       0  \n",
       "9985         96833.00       0  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[909 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['tenure'].isna()] # смотрим срез по пропускам, чтобы посмотреть, не прослеживается какая-то взаимосвязь с данными в других столбцах\n",
    "# явных зависимостей не прослеживается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rownumber</th>\n",
       "      <th>customerid</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rownumber    customerid   creditscore           age       tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
       "\n",
       "             balance  numofproducts    hascrcard  isactivemember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       estimatedsalary        exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() # смотрим числовые столбцы, нет ли по ним явных аномалий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Spain', 'Germany'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['geography'].unique() # смотрим, сколько есть уникальных стран в столбце \"география\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: geography, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['geography'].value_counts() # смотрим, как распределены данные по странам: выходит соотношение 2:1:1 по Франции - Германии -\n",
    "# Испании, неплозхо бы стратифицировать выборки соответственно, но я не уверен, что это необходимо в рамках данной задачи и как это\n",
    "# корректно сделать, да и все 3 страны члены ЕС и возможно различиями между их гражданами можно пренебречь в даннои проекте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9091 entries, 0 to 9998\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   rownumber        9091 non-null   int64  \n",
      " 1   customerid       9091 non-null   int64  \n",
      " 2   surname          9091 non-null   object \n",
      " 3   creditscore      9091 non-null   int64  \n",
      " 4   geography        9091 non-null   object \n",
      " 5   gender           9091 non-null   object \n",
      " 6   age              9091 non-null   int64  \n",
      " 7   tenure           9091 non-null   float64\n",
      " 8   balance          9091 non-null   float64\n",
      " 9   numofproducts    9091 non-null   int64  \n",
      " 10  hascrcard        9091 non-null   int64  \n",
      " 11  isactivemember   9091 non-null   int64  \n",
      " 12  estimatedsalary  9091 non-null   float64\n",
      " 13  exited           9091 non-null   int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna() # пропуски в столбце \"tenure\" составляют менее 10% и не хотелось бы портить зависимости, ставя заглушку, поэтому\n",
    "df.info() # удаляем строки с пропусками, проверяем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['exited'].unique()  #  проверяем уникальные значения целевого признака: только 1 и 0, аномалий нет, можно приступать к \n",
    "# решению задачи классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** Перед нами стоит задача классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.796062\n",
       "1    0.203938\n",
       "Name: exited, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_frequency = df['exited'].value_counts(normalize=True) # исследуем баланс классов\n",
    "\n",
    "class_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Баланс классов'}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_frequency.plot(kind='bar', title='Баланс классов')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** Наблюдается дисбаланс классов, положительный класс проявляется реже в соотношении 20:80 (или 1:4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(['rownumber', 'customerid', 'surname'], axis=1) # уберем лишние столбцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ohe = pd.get_dummies(data, drop_first=True) \n",
    "# преобразовываем категориальные признаки в численные техникой прямого кодирования (One-Hot Encoding) с избежанием дамми-ловушки\n",
    "# иначе модель не сможет обучиться на категориальных признаках\n",
    "features_logreg = data_ohe.drop(['exited'], axis=1) \n",
    "target_logreg = data_ohe['exited']\n",
    "# у нас ситуация, когда есть исходные данные и нужно их поделить на 3 выборки: делим в соотношении 3:1:1 (60%, 20%, 20%). \n",
    "# Метод train_test_split не дает возможности сразу разделить данные на 3 части, поэтому применяем его 2 раза последовательно:  \n",
    "features_train_valid_logreg, features_test_logreg, target_train_valid_logreg, target_test_logreg = train_test_split(\n",
    "    features_logreg, target_logreg, test_size=0.2, random_state=12345) # отделяем 20% данных для тестовой выборки\n",
    "features_train_logreg, features_valid_logreg, target_train_logreg, target_valid_logreg = train_test_split(\n",
    "    features_train_valid_logreg, target_train_valid_logreg, test_size=0.25, random_state=12345) # отделяем 20% (25% от оставшихся) \n",
    "                                                                                  # данных для валидационной выборки\n",
    "    \n",
    "numeric = ['creditscore', 'age', 'tenure','balance', 'numofproducts', 'estimatedsalary']\n",
    "# для логистической регрессии числовые признаки стандартизируем (масштабируем), чтобы у них были равные веса при тренировке модели\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train_logreg[numeric])\n",
    "features_train_logreg[numeric] = scaler.transform(features_train_logreg[numeric])\n",
    "features_valid_logreg[numeric] = scaler.transform(features_valid_logreg[numeric])\n",
    "features_test_logreg[numeric] = scaler.transform(features_test_logreg[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5454, 11)\n",
      "(1818, 11)\n",
      "(1819, 11)\n"
     ]
    }
   ],
   "source": [
    "print(features_train_logreg.shape) # проверяем, достаточны ли размеры выборок\n",
    "print(features_valid_logreg.shape)\n",
    "print(features_test_logreg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1-меры: 0.3004\n",
      "Значение AUC-ROC: 0.7726\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=12345, solver='liblinear') # обучаем логистическую регрессию без учета дисбаланса классов\n",
    "logreg.fit(features_train_logreg, target_train_logreg)\n",
    "predicted_valid_logreg = logreg.predict(features_valid_logreg)\n",
    "\n",
    "print('Значение F1-меры:', round(f1_score(target_valid_logreg, predicted_valid_logreg), 4)) # выводим значение F1 меры\n",
    "\n",
    "probabilities_valid_logreg = logreg.predict_proba(features_valid_logreg)\n",
    "probabilities_one_valid_logreg = probabilities_valid_logreg[:, 1]\n",
    "\n",
    "print('Значение AUC-ROC:', round(roc_auc_score(target_valid_logreg, probabilities_one_valid_logreg), 4)) # выводим значение AUC-ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для логистической регрессии без учета дисбаланса классов результаты следующие:** \n",
    "Метрика f1 довольно низкая, а значит качество прогноза положительного результата низкое хотя бы по одной из метрик (точность / полнота) или по обеим. AUC-ROC в 1.5 раза выше, чем у случайной модели, но еще есть, к чему стремиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4609.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>215.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5119.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5277.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5182.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>306.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4274.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>457.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3374.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3559.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9086</th>\n",
       "      <td>407.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7599.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>378.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4385.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4627.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>316.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>379.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4214.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9091 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      creditscore  geography  gender   age  tenure  balance  numofproducts  \\\n",
       "0           226.0        0.0     0.0  24.0     2.0      0.0            0.0   \n",
       "1           215.0        2.0     0.0  23.0     1.0    679.0            0.0   \n",
       "2           109.0        0.0     0.0  24.0     8.0   5277.0            2.0   \n",
       "3           306.0        0.0     0.0  21.0     1.0      0.0            1.0   \n",
       "4           457.0        2.0     0.0  25.0     2.0   3374.0            0.0   \n",
       "...           ...        ...     ...   ...     ...      ...            ...   \n",
       "9086        407.0        0.0     0.0  11.0     2.0      0.0            1.0   \n",
       "9087        378.0        0.0     1.0  21.0     5.0      0.0            1.0   \n",
       "9088        123.0        0.0     1.0  17.0    10.0    110.0            0.0   \n",
       "9089        316.0        0.0     0.0  18.0     7.0      0.0            0.0   \n",
       "9090        379.0        1.0     1.0  24.0     3.0    387.0            1.0   \n",
       "\n",
       "      hascrcard  isactivemember  estimatedsalary  exited  \n",
       "0           1.0             1.0           4609.0     1.0  \n",
       "1           0.0             1.0           5119.0     0.0  \n",
       "2           1.0             0.0           5182.0     1.0  \n",
       "3           0.0             0.0           4274.0     0.0  \n",
       "4           1.0             1.0           3559.0     0.0  \n",
       "...         ...             ...              ...     ...  \n",
       "9086        0.0             0.0           7599.0     0.0  \n",
       "9087        1.0             0.0           4385.0     0.0  \n",
       "9088        1.0             1.0           4627.0     0.0  \n",
       "9089        0.0             1.0           1882.0     1.0  \n",
       "9090        1.0             0.0           4214.0     1.0  \n",
       "\n",
       "[9091 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OrdinalEncoder() \n",
    "# хоть техника OHE и универсальная для разных моделей, но для дерева решений и случайного леса есть техника порядкового кодирования, \n",
    "# применим ее, поэтому для деревьев и леса поделим данные по новой, с учетом другой техники преобразования кат. признаков\n",
    "data_ordinal = pd.DataFrame(encoder.fit_transform(data), \n",
    "                                                      columns=data.columns)\n",
    "features_ranfor = data_ordinal.drop(['exited'], axis=1) \n",
    "target_ranfor = data_ordinal['exited']\n",
    "# у нас ситуация, когда есть исходные данные и нужно их поделить на 3 выборки: делим в соотношении 3:1:1 (60%, 20%, 20%). \n",
    "# Метод train_test_split не дает возможности сразу разделить данные на 3 части, поэтому применяем его 2 раза последовательно:  \n",
    "features_train_valid_ranfor, features_test_ranfor, target_train_valid_ranfor, target_test_ranfor = train_test_split(\n",
    "    features_ranfor, target_ranfor, test_size=0.2, random_state=12345) # отделяем 20% данных для тестовой выборки\n",
    "features_train_ranfor, features_valid_ranfor, target_train_ranfor, target_valid_ranfor = train_test_split(\n",
    "    features_train_valid_ranfor, target_train_valid_ranfor, test_size=0.25, random_state=12345) # отделяем 20% (25% от оставшихся) \n",
    "                                                                                  # данных для валидационной выборки\n",
    "data_ordinal # выводим получившийся датафрейм, чтобы оценить, что все прошло без ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 - оптимальная глубина дерева\n",
      "0.5303 - F1-мера лучшего дерева решений на валидационной выборке\n",
      "0.8141 - значение AUC-ROC\n"
     ]
    }
   ],
   "source": [
    "best_tree_model = None\n",
    "best_tree_f1 = 0\n",
    "best_tree_aucroc = 0\n",
    "best_tree_depth = 0\n",
    "for depth in range(1, 11):\n",
    "    detree = DecisionTreeClassifier(random_state=12345, max_depth=depth) \n",
    "    detree.fit(features_train_ranfor, target_train_ranfor) # обучаем модель на тренировочной выборке\n",
    "    predicted_valid_detree = detree.predict(features_valid_ranfor) # считаем метрики модели на валидационной выборке\n",
    "    f1 = round(f1_score(target_valid_ranfor, predicted_valid_detree), 4)\n",
    "    probabilities_valid_detree = detree.predict_proba(features_valid_ranfor)\n",
    "    probabilities_one_valid_detree = probabilities_valid_detree[:, 1]\n",
    "    aucroc = round(roc_auc_score(target_valid_ranfor, probabilities_one_valid_detree), 4)\n",
    "    if f1 > best_tree_f1:\n",
    "        best_tree_model = detree # сохраняем наилучшую модель\n",
    "        best_tree_f1 = f1 #  сохраняем наилучшее значение F1-меры на валидационных данных\n",
    "        best_tree_aucroc = aucroc #  сохраняем значение AUC-ROC лучшей модели на валидационных данных\n",
    "        best_tree_depth = depth #  сохраняем наилучшее значение гиперпараметра depth на валидационных данных\n",
    "print(best_tree_depth, '- оптимальная глубина дерева') \n",
    "print(best_tree_f1, '- F1-мера лучшего дерева решений на валидационной выборке')\n",
    "print(best_tree_aucroc, '- значение AUC-ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для дерева решений без учета дисбаланса классов результаты следующие:** \n",
    "Метрика f1 почти в 2 раза выше, чем для логистической регрессии, но все еще ниже целевого уровня в 0.59, а значит качество прогноза положительного результата пока ниже, чем хотелось бы. AUC-ROC немного выше, чем у логистической регрессии, но еще есть, к чему стремиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 - лучшее количество деревьев\n",
      "16 - лучшая глубина деревьев\n",
      "0.5597 - F1-мера лучшего случайного леса на валидационной выборке\n",
      "0.8257 - значение AUC-ROC\n"
     ]
    }
   ],
   "source": [
    "best_forest_model = None\n",
    "best_forest_f1 = 0\n",
    "best_forest_aucroc = 0\n",
    "best_forest_est = 0\n",
    "best_forest_depth = 0\n",
    "for est in range(10, 101, 10):\n",
    "    for depth in range (1, 21, 1):\n",
    "        ranfor = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        ranfor.fit(features_train_ranfor, target_train_ranfor) # обучаем модель на тренировочной выборке\n",
    "        predicted_valid_ranfor = ranfor.predict(features_valid_ranfor)\n",
    "        f1 = round(f1_score(target_valid_ranfor, predicted_valid_ranfor), 4) # считаем метрики модели на валидационной в-ке\n",
    "        probabilities_valid_ranfor = ranfor.predict_proba(features_valid_ranfor)\n",
    "        probabilities_one_valid_ranfor = probabilities_valid_ranfor[:, 1]\n",
    "        aucroc = round(roc_auc_score(target_valid_ranfor, probabilities_one_valid_ranfor), 4)\n",
    "        if f1 > best_forest_f1:\n",
    "            best_forest_model = ranfor # сохраняем наилучшую модель\n",
    "            best_forest_f1 = f1 #  сохраняем наилучшее значение F1-меры на валидационных данных\n",
    "            best_forest_aucroc = aucroc #  сохраняем значение AUC-ROC лучшей модели на валидационных данных\n",
    "            best_forest_est = est #  сохраняем наилучшее значение гиперпараметра n_estimators на валидационных данных\n",
    "            best_forest_depth = depth #  сохраняем наилучшее значение гиперпараметра depth на валидационных данных\n",
    "print(best_forest_est, '- лучшее количество деревьев')\n",
    "print(best_forest_depth, '- лучшая глубина деревьев') \n",
    "print(best_forest_f1, '- F1-мера лучшего случайного леса на валидационной выборке')\n",
    "print(best_forest_aucroc, '- значение AUC-ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для случайного леса классификации без учета дисбаланса классов результаты следующие:** \n",
    "Метрика f1 немного выше, чем для дерева решений, но все еще ниже целевого уровня в 0.59, а значит качество прогноза положительного результата пока ниже, чем хотелось бы. AUC-ROC немного выше, чем у дерева решений, но все еще есть, к чему стремиться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взвешивание классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1-меры: 0.4951\n",
      "Значение AUC-ROC: 0.7748\n"
     ]
    }
   ],
   "source": [
    "# обучаем логистическую регрессию c учетом дисбаланса классов\n",
    "\n",
    "logreg = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced') \n",
    "logreg.fit(features_train_logreg, target_train_logreg)\n",
    "predicted_valid_logreg = logreg.predict(features_valid_logreg)\n",
    "\n",
    "print('Значение F1-меры:', round(f1_score(target_valid_logreg, predicted_valid_logreg), 4)) # выводим значение F1 меры\n",
    "\n",
    "probabilities_valid_logreg = logreg.predict_proba(features_valid_logreg)\n",
    "probabilities_one_valid_logreg = probabilities_valid_logreg[:, 1]\n",
    "\n",
    "print('Значение AUC-ROC:', round(roc_auc_score(target_valid_logreg, probabilities_one_valid_logreg), 4)) # выводим значение AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 - оптимальная глубина дерева\n",
      "0.5624 - F1-мера лучшего дерева решений на валидационной выборке\n",
      "0.8126 - значение AUC-ROC\n"
     ]
    }
   ],
   "source": [
    "best_tree_model = None\n",
    "best_tree_f1 = 0\n",
    "best_tree_aucroc = 0\n",
    "best_tree_depth = 0\n",
    "for depth in range(1, 11):\n",
    "    detree = DecisionTreeClassifier(random_state=12345, max_depth=depth, class_weight='balanced') \n",
    "    detree.fit(features_train_ranfor, target_train_ranfor) # обучаем модель на тренировочной выборке\n",
    "    predicted_valid_detree = detree.predict(features_valid_ranfor) # считаем метрики модели на валидационной выборке\n",
    "    f1 = round(f1_score(target_valid_ranfor, predicted_valid_detree), 4)\n",
    "    probabilities_valid_detree = detree.predict_proba(features_valid_ranfor)\n",
    "    probabilities_one_valid_detree = probabilities_valid_detree[:, 1]\n",
    "    aucroc = round(roc_auc_score(target_valid_ranfor, probabilities_one_valid_detree), 4)\n",
    "    if f1 > best_tree_f1:\n",
    "        best_tree_model = detree # сохраняем наилучшую модель\n",
    "        best_tree_f1 = f1 #  сохраняем наилучшее значение F1-меры на валидационных данных\n",
    "        best_tree_aucroc = aucroc #  сохраняем значение AUC-ROC лучшей модели на валидационных данных\n",
    "        best_tree_depth = depth #  сохраняем наилучшее значение гиперпараметра depth на валидационных данных\n",
    "print(best_tree_depth, '- оптимальная глубина дерева') \n",
    "print(best_tree_f1, '- F1-мера лучшего дерева решений на валидационной выборке')\n",
    "print(best_tree_aucroc, '- значение AUC-ROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 - лучшее количество деревьев\n",
      "8 - лучшая глубина деревьев\n",
      "0.6018 - F1-мера лучшего случайного леса на валидационной выборке\n",
      "0.8473 - значение AUC-ROC\n"
     ]
    }
   ],
   "source": [
    "best_forest_model = None\n",
    "best_forest_f1 = 0\n",
    "best_forest_aucroc = 0\n",
    "best_forest_est = 0\n",
    "best_forest_depth = 0\n",
    "for est in range(10, 101, 10):\n",
    "    for depth in range (1, 21, 1):\n",
    "        ranfor = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth, class_weight='balanced')\n",
    "        ranfor.fit(features_train_ranfor, target_train_ranfor) # обучаем модель на тренировочной выборке\n",
    "        predicted_valid_ranfor = ranfor.predict(features_valid_ranfor)\n",
    "        f1 = round(f1_score(target_valid_ranfor, predicted_valid_ranfor), 4) # считаем метрики модели на валидационной в-ке\n",
    "        probabilities_valid_ranfor = ranfor.predict_proba(features_valid_ranfor)\n",
    "        probabilities_one_valid_ranfor = probabilities_valid_ranfor[:, 1]\n",
    "        aucroc = round(roc_auc_score(target_valid_ranfor, probabilities_one_valid_ranfor), 4)\n",
    "        if f1 > best_forest_f1:\n",
    "            best_forest_model = ranfor # сохраняем наилучшую модель\n",
    "            best_forest_f1 = f1 #  сохраняем наилучшее значение F1-меры на валидационных данных\n",
    "            best_forest_aucroc = aucroc #  сохраняем значение AUC-ROC лучшей модели на валидационных данных\n",
    "            best_forest_est = est #  сохраняем наилучшее значение гиперпараметра n_estimators на валидационных данных\n",
    "            best_forest_depth = depth #  сохраняем наилучшее значение гиперпараметра depth на валидационных данных\n",
    "print(best_forest_est, '- лучшее количество деревьев')\n",
    "print(best_forest_depth, '- лучшая глубина деревьев') \n",
    "print(best_forest_f1, '- F1-мера лучшего случайного леса на валидационной выборке')\n",
    "print(best_forest_aucroc, '- значение AUC-ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** для случайного леса оказалось достаточным применить гиперпараметр class_weight='balanced', чтобы учесть дисбаланс классов и достичь значения F1-меры выше 0.59 (пока на валидационной выборке). Далее проверим его на тестовой выборке. Для логистической регрессии и дерева решений данный гиперпараметр улучшил показатели, но они по прежнему ниже требуемого уровня. Попробуем другие способы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объявим функцию, которая увеличит кол-во положительного признака в обучающей выборке и перемешает данные, подготовив к обучению\n",
    "# кол-во положительного класса увеличиваем в 4 раза, исходя из результатов исследования баланса классов выше\n",
    "\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1-меры: 0.4957\n"
     ]
    }
   ],
   "source": [
    "# обучаем логистическую регрессию с учетом увеличенной выборки\n",
    "\n",
    "features_upsampled_logreg, target_upsampled_logreg = upsample(features_train_logreg, target_train_logreg, 4)\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=12345)\n",
    "\n",
    "logreg.fit(features_upsampled_logreg, target_upsampled_logreg)\n",
    "\n",
    "predicted_valid_logreg = logreg.predict(features_valid_logreg)\n",
    "\n",
    "print('Значение F1-меры:', round(f1_score(target_valid_logreg, predicted_valid_logreg), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** При увеличении выборки метрика F1 для логистической регрессии еще немного увеличилась по сравнению со взвешиванием классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для дерева решений и случайного леса делаем увеличение выборки отдельно\n",
    "\n",
    "features_upsampled_ranfor, target_upsampled_ranfor = upsample(features_train_ranfor, target_train_ranfor, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 - оптимальная глубина дерева\n",
      "0.5624 - F1-мера лучшего дерева решений на валидационной выборке\n",
      "0.8126 - значение AUC-ROC\n"
     ]
    }
   ],
   "source": [
    "best_tree_model = None\n",
    "best_tree_f1 = 0\n",
    "best_tree_aucroc = 0\n",
    "best_tree_depth = 0\n",
    "for depth in range(1, 11):\n",
    "    detree = DecisionTreeClassifier(random_state=12345, max_depth=depth) \n",
    "    detree.fit(features_upsampled_ranfor, target_upsampled_ranfor) # обучаем модель на тренировочной выборке\n",
    "    predicted_valid_detree = detree.predict(features_valid_ranfor) # считаем метрики модели на валидационной выборке\n",
    "    f1 = round(f1_score(target_valid_ranfor, predicted_valid_detree), 4)\n",
    "    probabilities_valid_detree = detree.predict_proba(features_valid_ranfor)\n",
    "    probabilities_one_valid_detree = probabilities_valid_detree[:, 1]\n",
    "    aucroc = round(roc_auc_score(target_valid_ranfor, probabilities_one_valid_detree), 4)\n",
    "    if f1 > best_tree_f1:\n",
    "        best_tree_model = detree # сохраняем наилучшую модель\n",
    "        best_tree_f1 = f1 #  сохраняем наилучшее значение F1-меры на валидационных данных\n",
    "        best_tree_aucroc = aucroc #  сохраняем значение AUC-ROC лучшей модели на валидационных данных\n",
    "        best_tree_depth = depth #  сохраняем наилучшее значение гиперпараметра depth на валидационных данных\n",
    "print(best_tree_depth, '- оптимальная глубина дерева') \n",
    "print(best_tree_f1, '- F1-мера лучшего дерева решений на валидационной выборке')\n",
    "print(best_tree_aucroc, '- значение AUC-ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** При увеличении выборки метрика F1 для дерева решения такая же, как при взвешивании классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 - лучшее количество деревьев\n",
      "18 - лучшая глубина деревьев\n",
      "0.5942 - F1-мера лучшего случайного леса на валидационной выборке\n",
      "0.835 - значение AUC-ROC\n"
     ]
    }
   ],
   "source": [
    "best_forest_model = None\n",
    "best_forest_f1 = 0\n",
    "best_forest_aucroc = 0\n",
    "best_forest_est = 0\n",
    "best_forest_depth = 0\n",
    "for est in range(10, 101, 10):\n",
    "    for depth in range (1, 21, 1):\n",
    "        ranfor = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        ranfor.fit(features_upsampled_ranfor, target_upsampled_ranfor) # обучаем модель на тренировочной выборке\n",
    "        predicted_valid_ranfor = ranfor.predict(features_valid_ranfor)\n",
    "        f1 = round(f1_score(target_valid_ranfor, predicted_valid_ranfor), 4) # считаем метрики модели на валидационной в-ке\n",
    "        probabilities_valid_ranfor = ranfor.predict_proba(features_valid_ranfor)\n",
    "        probabilities_one_valid_ranfor = probabilities_valid_ranfor[:, 1]\n",
    "        aucroc = round(roc_auc_score(target_valid_ranfor, probabilities_one_valid_ranfor), 4)\n",
    "        if f1 > best_forest_f1:\n",
    "            best_forest_model = ranfor # сохраняем наилучшую модель\n",
    "            best_forest_f1 = f1 #  сохраняем наилучшее значение F1-меры на валидационных данных\n",
    "            best_forest_aucroc = aucroc #  сохраняем значение AUC-ROC лучшей модели на валидационных данных\n",
    "            best_forest_est = est #  сохраняем наилучшее значение гиперпараметра n_estimators на валидационных данных\n",
    "            best_forest_depth = depth #  сохраняем наилучшее значение гиперпараметра depth на валидационных данных\n",
    "print(best_forest_est, '- лучшее количество деревьев')\n",
    "print(best_forest_depth, '- лучшая глубина деревьев') \n",
    "print(best_forest_f1, '- F1-мера лучшего случайного леса на валидационной выборке')\n",
    "print(best_forest_aucroc, '- значение AUC-ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** При увеличении выборки метрика F1 для случайного леса хуже, чем при взвешивании классов, однако тоже выше требуемого значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объявим функцию, которая уменьшит кол-во отрицательного признака в обучающей выборке и перемешает данные, подготовив к обучению\n",
    "# кол-во отрицательного класса уменьшаем в 4 раза, исходя из результатов исследования баланса классов выше\n",
    "\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1-меры: 0.5\n"
     ]
    }
   ],
   "source": [
    "# обучаем логистическую регрессию с учетом уменьшенной выборки\n",
    "\n",
    "features_downsampled_logreg, target_downsampled_logreg = downsample(features_train_logreg, target_train_logreg, 0.25)\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=12345)\n",
    "logreg.fit(features_downsampled_logreg, target_downsampled_logreg)\n",
    "\n",
    "predicted_valid_logreg = logreg.predict(features_valid_logreg)\n",
    "\n",
    "print('Значение F1-меры:', round(f1_score(target_valid_logreg, predicted_valid_logreg), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** При уменьшении выборки для логистической регрессии, метрика F1 еще немного увеличилась по сравнению с увеличением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для дерева решений и случайного леса делаем уменьшение выборки отдельно\n",
    "\n",
    "features_downsampled_ranfor, target_downsampled_ranfor = downsample(features_train_ranfor, target_train_ranfor, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 - оптимальная глубина дерева\n",
      "0.5532 - F1-мера лучшего дерева решений на валидационной выборке\n",
      "0.8095 - значение AUC-ROC\n"
     ]
    }
   ],
   "source": [
    "best_tree_model = None\n",
    "best_tree_f1 = 0\n",
    "best_tree_aucroc = 0\n",
    "best_tree_depth = 0\n",
    "for depth in range(1, 11):\n",
    "    detree = DecisionTreeClassifier(random_state=12345, max_depth=depth) \n",
    "    detree.fit(features_downsampled_ranfor, target_downsampled_ranfor) # обучаем модель на тренировочной выборке\n",
    "    predicted_valid_detree = detree.predict(features_valid_ranfor) # считаем метрики модели на валидационной выборке\n",
    "    f1 = round(f1_score(target_valid_ranfor, predicted_valid_detree), 4)\n",
    "    probabilities_valid_detree = detree.predict_proba(features_valid_ranfor)\n",
    "    probabilities_one_valid_detree = probabilities_valid_detree[:, 1]\n",
    "    aucroc = round(roc_auc_score(target_valid_ranfor, probabilities_one_valid_detree), 4)\n",
    "    if f1 > best_tree_f1:\n",
    "        best_tree_model = detree # сохраняем наилучшую модель\n",
    "        best_tree_f1 = f1 #  сохраняем наилучшее значение F1-меры на валидационных данных\n",
    "        best_tree_aucroc = aucroc #  сохраняем значение AUC-ROC лучшей модели на валидационных данных\n",
    "        best_tree_depth = depth #  сохраняем наилучшее значение гиперпараметра depth на валидационных данных\n",
    "print(best_tree_depth, '- оптимальная глубина дерева') \n",
    "print(best_tree_f1, '- F1-мера лучшего дерева решений на валидационной выборке')\n",
    "print(best_tree_aucroc, '- значение AUC-ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** При уменьшении выборки метрика F1 для дерева решений ухудшилась по сравнению с увеличением выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 - лучшее количество деревьев\n",
      "16 - лучшая глубина деревьев\n",
      "0.5845 - F1-мера лучшего случайного леса на валидационной выборке\n",
      "0.8331 - значение AUC-ROC\n"
     ]
    }
   ],
   "source": [
    "best_forest_model = None\n",
    "best_forest_f1 = 0\n",
    "best_forest_aucroc = 0\n",
    "best_forest_est = 0\n",
    "best_forest_depth = 0\n",
    "for est in range(10, 101, 10):\n",
    "    for depth in range (1, 21, 1):\n",
    "        ranfor = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        ranfor.fit(features_downsampled_ranfor, target_downsampled_ranfor) # обучаем модель на тренировочной выборке\n",
    "        predicted_valid_ranfor = ranfor.predict(features_valid_ranfor)\n",
    "        f1 = round(f1_score(target_valid_ranfor, predicted_valid_ranfor), 4) # считаем метрики модели на валидационной в-ке\n",
    "        probabilities_valid_ranfor = ranfor.predict_proba(features_valid_ranfor)\n",
    "        probabilities_one_valid_ranfor = probabilities_valid_ranfor[:, 1]\n",
    "        aucroc = round(roc_auc_score(target_valid_ranfor, probabilities_one_valid_ranfor), 4)\n",
    "        if f1 > best_forest_f1:\n",
    "            best_forest_model = ranfor # сохраняем наилучшую модель\n",
    "            best_forest_f1 = f1 #  сохраняем наилучшее значение F1-меры на валидационных данных\n",
    "            best_forest_aucroc = aucroc #  сохраняем значение AUC-ROC лучшей модели на валидационных данных\n",
    "            best_forest_est = est #  сохраняем наилучшее значение гиперпараметра n_estimators на валидационных данных\n",
    "            best_forest_depth = depth #  сохраняем наилучшее значение гиперпараметра depth на валидационных данных\n",
    "print(best_forest_est, '- лучшее количество деревьев')\n",
    "print(best_forest_depth, '- лучшая глубина деревьев') \n",
    "print(best_forest_f1, '- F1-мера лучшего случайного леса на валидационной выборке')\n",
    "print(best_forest_aucroc, '- значение AUC-ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** При уменьшении выборки метрика F1 для случайного леса ухудшилась по сравнению с увеличением выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изменение порога"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | F1-мера = 0.3352, Точность = 0.2013, Полнота = 1.0000\n",
      "Порог = 0.02 | F1-мера = 0.3347, Точность = 0.2011, Полнота = 0.9973\n",
      "Порог = 0.04 | F1-мера = 0.3435, Точность = 0.2079, Полнота = 0.9863\n",
      "Порог = 0.06 | F1-мера = 0.3685, Точность = 0.2273, Полнота = 0.9727\n",
      "Порог = 0.08 | F1-мера = 0.3964, Точность = 0.2500, Полнота = 0.9563\n",
      "Порог = 0.10 | F1-мера = 0.4188, Точность = 0.2706, Полнота = 0.9262\n",
      "Порог = 0.12 | F1-мера = 0.4411, Точность = 0.2949, Полнота = 0.8743\n",
      "Порог = 0.14 | F1-мера = 0.4539, Точность = 0.3119, Полнота = 0.8333\n",
      "Порог = 0.16 | F1-мера = 0.4711, Точность = 0.3357, Полнота = 0.7896\n",
      "Порог = 0.18 | F1-мера = 0.4777, Точность = 0.3514, Полнота = 0.7459\n",
      "Порог = 0.20 | F1-мера = 0.4828, Точность = 0.3717, Полнота = 0.6885\n",
      "Порог = 0.22 | F1-мера = 0.4974, Точность = 0.3987, Полнота = 0.6612\n",
      "Порог = 0.24 | F1-мера = 0.4939, Точность = 0.4165, Полнота = 0.6066\n",
      "Порог = 0.26 | F1-мера = 0.4988, Точность = 0.4396, Полнота = 0.5765\n",
      "Порог = 0.28 | F1-мера = 0.4840, Точность = 0.4554, Полнота = 0.5164\n",
      "Порог = 0.30 | F1-мера = 0.4824, Точность = 0.4785, Полнота = 0.4863\n",
      "Порог = 0.32 | F1-мера = 0.4864, Точность = 0.5105, Полнота = 0.4645\n",
      "Порог = 0.34 | F1-мера = 0.4646, Точность = 0.5185, Полнота = 0.4208\n",
      "Порог = 0.36 | F1-мера = 0.4381, Точность = 0.5227, Полнота = 0.3770\n",
      "Порог = 0.38 | F1-мера = 0.4172, Точность = 0.5294, Полнота = 0.3443\n"
     ]
    }
   ],
   "source": [
    "# для обученной догистической регрессии переберем значения порога и посмотрим, как они вияют на значение F1-меры:\n",
    "\n",
    "logreg = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "logreg.fit(features_train_logreg, target_train_logreg)\n",
    "probabilities_valid_logreg = logreg.predict_proba(features_valid_logreg)\n",
    "probabilities_one_valid_logreg = probabilities_valid_logreg[:, 1]\n",
    "\n",
    "for threshold in np.arange(0, 0.4, 0.02):\n",
    "    predicted_valid_logreg = probabilities_one_valid_logreg > threshold  \n",
    "    f1_logreg = f1_score(target_valid_logreg, predicted_valid_logreg)\n",
    "    precision_logreg = precision_score(target_valid_logreg, predicted_valid_logreg)\n",
    "    recall_logreg = recall_score(target_valid_logreg, predicted_valid_logreg)\n",
    "    \n",
    "    print(\"Порог = {:.2f} | F1-мера = {:.4f}, Точность = {:.4f}, Полнота = {:.4f}\".format(\n",
    "        threshold, f1_logreg, precision_logreg, recall_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** При изменении порога не удалось добиться улучшения метрики F1 по сравнению с уменьшением выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | F1-мера = 0.3344, Точность = 0.2009, Полнота = 0.9973\n",
      "Порог = 0.02 | F1-мера = 0.3643, Точность = 0.2231, Полнота = 0.9918\n",
      "Порог = 0.04 | F1-мера = 0.3964, Точность = 0.2504, Полнота = 0.9508\n",
      "Порог = 0.06 | F1-мера = 0.4278, Точность = 0.2784, Полнота = 0.9235\n",
      "Порог = 0.08 | F1-мера = 0.4251, Точность = 0.2769, Полнота = 0.9153\n",
      "Порог = 0.10 | F1-мера = 0.4648, Точность = 0.3152, Полнота = 0.8852\n",
      "Порог = 0.12 | F1-мера = 0.4648, Точность = 0.3152, Полнота = 0.8852\n",
      "Порог = 0.14 | F1-мера = 0.4823, Точность = 0.3358, Полнота = 0.8552\n",
      "Порог = 0.16 | F1-мера = 0.4871, Точность = 0.3451, Полнота = 0.8279\n",
      "Порог = 0.18 | F1-мера = 0.5230, Точность = 0.4119, Полнота = 0.7158\n",
      "Порог = 0.20 | F1-мера = 0.5230, Точность = 0.4119, Полнота = 0.7158\n",
      "Порог = 0.22 | F1-мера = 0.5230, Точность = 0.4119, Полнота = 0.7158\n",
      "Порог = 0.24 | F1-мера = 0.5515, Точность = 0.5407, Полнота = 0.5628\n",
      "Порог = 0.26 | F1-мера = 0.5515, Точность = 0.5407, Полнота = 0.5628\n",
      "Порог = 0.28 | F1-мера = 0.5673, Точность = 0.5964, Полнота = 0.5410\n",
      "Порог = 0.30 | F1-мера = 0.5673, Точность = 0.5964, Полнота = 0.5410\n",
      "Порог = 0.32 | F1-мера = 0.5673, Точность = 0.5964, Полнота = 0.5410\n",
      "Порог = 0.34 | F1-мера = 0.5673, Точность = 0.5964, Полнота = 0.5410\n",
      "Порог = 0.36 | F1-мера = 0.5673, Точность = 0.5964, Полнота = 0.5410\n",
      "Порог = 0.38 | F1-мера = 0.5673, Точность = 0.5964, Полнота = 0.5410\n",
      "Порог = 0.40 | F1-мера = 0.5673, Точность = 0.5964, Полнота = 0.5410\n",
      "Порог = 0.42 | F1-мера = 0.5673, Точность = 0.5964, Полнота = 0.5410\n",
      "Порог = 0.44 | F1-мера = 0.5673, Точность = 0.5964, Полнота = 0.5410\n",
      "Порог = 0.46 | F1-мера = 0.5303, Точность = 0.7251, Полнота = 0.4180\n",
      "Порог = 0.48 | F1-мера = 0.5303, Точность = 0.7251, Полнота = 0.4180\n"
     ]
    }
   ],
   "source": [
    "# для обученного дерева решений переберем значения порога и посмотрим, как они вияют на значение F1-меры:\n",
    "\n",
    "detree = DecisionTreeClassifier(max_depth=5, random_state=12345)\n",
    "detree.fit(features_train_ranfor, target_train_ranfor)\n",
    "probabilities_valid_detree = detree.predict_proba(features_valid_ranfor)\n",
    "probabilities_one_valid_detree = probabilities_valid_detree[:, 1]\n",
    "\n",
    "for threshold in np.arange(0, 0.5, 0.02):\n",
    "    predicted_valid_detree = probabilities_one_valid_detree > threshold # \n",
    "    f1_detree = f1_score(target_valid_ranfor, predicted_valid_detree) # \n",
    "    precision_detree = precision_score(target_valid_ranfor, predicted_valid_detree)\n",
    "    recall_detree = recall_score(target_valid_ranfor, predicted_valid_detree)\n",
    "    \n",
    "    print(\"Порог = {:.2f} | F1-мера = {:.4f}, Точность = {:.4f}, Полнота = {:.4f}\".format(\n",
    "        threshold, f1_detree, precision_detree, recall_detree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** При изменении порога для дерева решений возможно добиться небольшого улучшения метрики F1 по сравнению со взвешиванием классов, однако целевой показатель меры все равно не достигнут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | F1-мера = 0.3603, Точность = 0.2199, Полнота = 0.9973\n",
      "Порог = 0.02 | F1-мера = 0.3766, Точность = 0.2328, Полнота = 0.9863\n",
      "Порог = 0.04 | F1-мера = 0.4091, Точность = 0.2602, Полнота = 0.9563\n",
      "Порог = 0.06 | F1-мера = 0.4336, Точность = 0.2833, Полнота = 0.9235\n",
      "Порог = 0.08 | F1-мера = 0.4544, Точность = 0.3057, Полнота = 0.8852\n",
      "Порог = 0.10 | F1-мера = 0.4737, Точность = 0.3268, Полнота = 0.8607\n",
      "Порог = 0.12 | F1-мера = 0.4841, Точность = 0.3412, Полнота = 0.8333\n",
      "Порог = 0.14 | F1-мера = 0.4949, Точность = 0.3582, Полнота = 0.8005\n",
      "Порог = 0.16 | F1-мера = 0.5098, Точность = 0.3783, Полнота = 0.7814\n",
      "Порог = 0.18 | F1-мера = 0.5217, Точность = 0.3988, Полнота = 0.7541\n",
      "Порог = 0.20 | F1-мера = 0.5387, Точность = 0.4261, Полнота = 0.7322\n",
      "Порог = 0.22 | F1-мера = 0.5468, Точность = 0.4444, Полнота = 0.7104\n",
      "Порог = 0.24 | F1-мера = 0.5559, Точность = 0.4674, Полнота = 0.6858\n",
      "Порог = 0.26 | F1-мера = 0.5612, Точность = 0.4860, Полнота = 0.6639\n",
      "Порог = 0.28 | F1-мера = 0.5749, Точность = 0.5152, Полнота = 0.6503\n",
      "Порог = 0.30 | F1-мера = 0.5884, Точность = 0.5469, Полнота = 0.6366\n",
      "Порог = 0.32 | F1-мера = 0.5852, Точность = 0.5583, Полнота = 0.6148\n",
      "Порог = 0.34 | F1-мера = 0.5757, Точность = 0.5749, Полнота = 0.5765\n",
      "Порог = 0.36 | F1-мера = 0.5755, Точность = 0.5948, Полнота = 0.5574\n",
      "Порог = 0.38 | F1-мера = 0.5723, Точность = 0.6144, Полнота = 0.5355\n"
     ]
    }
   ],
   "source": [
    "# для обученного случайного леса переберем значения порога и посмотрим, как они вияют на значение F1-меры:\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators=40, max_depth=16, random_state=12345)\n",
    "ranfor.fit(features_train_ranfor, target_train_ranfor)\n",
    "probabilities_valid_ranfor = ranfor.predict_proba(features_valid_ranfor)\n",
    "probabilities_one_valid_ranfor = probabilities_valid_ranfor[:, 1]\n",
    "\n",
    "for threshold in np.arange(0, 0.4, 0.02):\n",
    "    predicted_valid_ranfor = probabilities_one_valid_ranfor > threshold \n",
    "    f1_ranfor = f1_score(target_valid_ranfor, predicted_valid_ranfor) \n",
    "    precision_ranfor = precision_score(target_valid_ranfor, predicted_valid_ranfor)\n",
    "    recall_ranfor = recall_score(target_valid_ranfor, predicted_valid_ranfor)\n",
    "    \n",
    "    print(\"Порог = {:.2f} | F1-мера = {:.4f}, Точность = {:.4f}, Полнота = {:.4f}\".format(\n",
    "        threshold, f1_ranfor, precision_ranfor, recall_ranfor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** При изменении порога для случайного леса точно возможно добиться улучшения метрики F1 по сравнению с увеличением и уменьшением выборки, однако целевой показатель меры все равно не достигнут. Можно было бы еще поэкспериментировать с изменением параметров, однако метод взвешивания классов проще и уже дал нам нужный результат. Переходим к тестированию лучшей модели. Если оно не подтвердит результат, то будем искать дальше. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Промежуточный вывод:** Итак, если для логистической регрессии худший показатель F1-меры достигнут при взвешивании классов (0.4951), а лучший при уменьшении выборки (0.5), то для \"деревянных\" моделей, наоборот: уменьшение выборки дает худший результат (0.5532 для дерева и 0.5845 для леса), а лучший показатель F1-меры достигается при взвешивании классов (0.5624 для дерева и 0.6018 для леса), однако, стоит оговориться, что для дерева решений показатель при увеличении выборки такой же, как и при взвешивании классов, а для случайного леса он хоть и несколько ниже (0.5942), но тоже достигает заданного минимального уровня.\n",
    "Лучшей моделью, согласно проверке на валидационной выборке, стал случайный лес с количеством деревьев 80 и максимальной глубиной 8 с использованием тактики взвешивания классов для борьбы с дисбалансом. Проверим ее на тестовой выборке и сравним с константной моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1-меры: 0.5943\n",
      "Значение AUC-ROC: 0.8528\n"
     ]
    }
   ],
   "source": [
    "# обучаем случайный лес с учетом дисбаланса классов, используя гиперпараметры подобранные ранее и проверяем на тестовой выборке\n",
    "\n",
    "ranfor = RandomForestClassifier(n_estimators=80, max_depth=8, random_state=12345, class_weight='balanced')\n",
    "ranfor.fit(features_train_ranfor, target_train_ranfor)\n",
    "predicted_test_ranfor = ranfor.predict(features_test_ranfor)\n",
    "\n",
    "print('Значение F1-меры:', round(f1_score(target_test_ranfor, predicted_test_ranfor), 4)) \n",
    "\n",
    "probabilities_test_ranfor = ranfor.predict_proba(features_test_ranfor)\n",
    "probabilities_one_test_ranfor = probabilities_test_ranfor[:, 1]\n",
    "\n",
    "print('Значение AUC-ROC:', round(roc_auc_score(target_test_ranfor, probabilities_one_test_ranfor), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Комментарий:** Цель достигнута - F1-мера выше 0.59. AUC-ROC 0.85 - это, конечно не 1, но достаточно хороший результат. Сравним нашу модель с константной (которая предсказывает все время одно значение - 1, так как для бизнес задачи нам требуется предсказать отток клиентов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение F1-меры для константной модели: 0.3373\n",
      "Значение AUC-ROC для константной модели: 0.5\n"
     ]
    }
   ],
   "source": [
    "target_pred_constant = pd.Series([1] * len(target_test_ranfor))\n",
    "print('Значение F1-меры для константной модели:', round(f1_score(target_test_ranfor, target_pred_constant), 4))\n",
    "\n",
    "probabilities_one_test_constant = pd.Series([1] * len(target_test_ranfor))\n",
    "\n",
    "print('Значение AUC-ROC для константной модели:', round(roc_auc_score(target_test_ranfor, probabilities_one_test_constant), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** Цель достигнута - F1-мера нашей модели при проверке на тестовой выборке выше 0.59. Наша модель на 75% превосходит константную по значению F1-меры и на 70% по значению AUC-ROC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
